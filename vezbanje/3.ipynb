{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fff4e136-6ae7-4301-8b48-3855fd2327d0",
   "metadata": {},
   "source": [
    "# Stabla odlucivanja\n",
    "\n",
    "Imamo X koje predstavlja neki skup atributa i y koja je ciljna promenljiva.\n",
    "Kod regresije y je neprekidan interval, a kod klasifikacije to je skup neuredjenih diskretnih vrednosti. Klasifikacijom cemo se baviti tokom ostatka kursa.\n",
    "\n",
    "Mi zelimo da iztreniramo model da koji ce na osnovu X-a da predvijda y.\n",
    "Model moze i da gresi, kako da vidimo koliko je model dobar?\n",
    "Mozemo da merimo:\n",
    "- **Tacnost (accuracy)** = broj_tacnih/broj_ukupnih - da bi ova mera bila dobra - treba da podelimo X na skup za treniranje i na testiranje. Ako to ne uradimo moze doci do:\n",
    "    - **Preprilagođavanje (overfitting)**\n",
    "        - Model se previše prilagođava trening skupu, gubi sposobnost generalizacije  \n",
    "    - **Potprilagođavanje (underfitting)**\n",
    "        - Model ne uspeva da se prilagodi čak ni trening podacima\n",
    "- **Stopa greske (error rate)** = broj_promasaja/broj_ukupnih\n",
    "  \n",
    "Ovo je bila uopstena prica za klasifikaciju, mi cemo se ovde fokusirati na stabla odlucivanja. Kod stabla odlucivanja - stablo je sam model. Imamo u svakom cvoru neki atribut i uslov za taj atribut (tako reci neke odluke), u odnosu da li je uslov tacan ili netacan idemo levom ili desnom granom do dece.\n",
    "\n",
    "Ako je u jednom cvoru nalazi podksup u kome 100% instanci pripada jednoj klasi za taj cvor kazemo da **cist**. Uvek mozemo podeliti stablo tako da svi cvorovi budu cisti ali ovo je upravo problem preprilagodjavanja ili overfittinga. Ne treba dubiti stablo zbog pojedinacnih primera koji su mozda greska ili sum. Da bi izbegli ovo mozemo da ogranicimo dubinu, mozemo i malo sofisticiranije da pustimo drvo da raste ali ako vidimo da nam ne odgovara, mozemo da posecemo neke grane - ovo se zove **pruning**.\n",
    "\n",
    "Da li ova stabla moraju da budu binarna? -> odgovor je NE.\n",
    "\n",
    "**1. Ginijev indeks**  \n",
    "$$Gini(t) = 1 - \\sum_j (p(j|t))^2$$\n",
    "\n",
    "**2. Entropija**  \n",
    "$$Entropy(t) = - \\sum_j p(j|t) \\cdot \\log_2(p(j|t))$$\n",
    "\n",
    "**3. Greška klasifikacije**  \n",
    "$$Error(t) = 1 - \\max_j p(j|t)$$\n",
    "\n",
    "Gini i entropija su dobre mere za pohlepni algoritam formiranja ovog stabla, on ne garantuje globalno optimalno resenje, ali globalno optimalno resenje je skoro nemoguce (jako tesko) naci, odatle nam je ovo dovoljno dobro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
